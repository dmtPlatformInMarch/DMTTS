# ğŸ—£ï¸ DMTTS: Multi-Language Text-to-Speech System  

DMTTS is a VITS-based multilingual text-to-speech toolkit.
---

## ğŸŒ Supported Languages
DMTTS supports **English**, **Chinese**, **Korean**, **Japanese**, **Vietnamese**, and **Thai**.  
Each language is currently represented by **a single speaker**.

---

## âš™ï¸ Environment Setup

### Using Conda
```bash
conda create -n dmtts python=3.11
conda activate dmtts
```

### Simple Installation
```bash
pip install git+https://github.com/dmtPlatformInMarch/DMTTS.git 
```

#### if Ubuntu 22.04 
```bash
pip install git+https://github.com/dmtPlatformInMarch/DMTTS.git@ubuntu.22.04
```

#### if Ubuntu 20.04
```bash
pip install git+https://github.com/dmtPlatformInMarch/DMTTS.git@ubuntu.20.04

```

### for japanese, additionally
```bash
pip install git+https://github.com/JRMeyer/jphones.git
python -m unidic download
```

---

## ğŸš€ Quick Start

```python
from dmtts.app.api import TTS

# Default text for each language
DEFAULT_TEXT = {
    "EN": "Did you ever hear a folk tale about a giant turtle?",
    "ZH": "é¢†åŸŸè¿‘å¹´æ¥å‘å±•è¿…é€Ÿã€‚",
    "KR": "ìµœê·¼, í…ìŠ¤íŠ¸ ìŒì„± í•©ì„± ë¶„ì•¼ê°€ ê¸‰ì†ë„ë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
    "VI": "xÃ¢m háº¡i tÃ¬nh dá»¥c tráº» em lÃ  váº¥n Ä‘á» cá»§a toÃ n cáº§u",
    "TH": "à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸«à¸¥à¸±à¸‡à¸¡à¸²à¸™à¸µà¹‰ à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸ªà¸±à¸‡à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸à¸¹à¸”à¹„à¸”à¹‰à¸à¸±à¸’à¸™à¸²à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§",
    "JP": "ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ã®åˆ†é‡ã¯æœ€è¿‘æ€¥é€Ÿãªç™ºå±•ã‚’é‚ã’ã¦ã„ã¾ã™ã€‚",
}

LANG_TO_LOCAL_REPO_ID = {
    'EN': 'path/to/your/local/path',
    'JP': 'path/to/your/local/path',
    'ZH': 'path/to/your/local/path',
    'KR': 'path/to/your/local/path',
    'TH': 'path/to/your/local/path',
    'VI': 'path/to/your/local/path',
}
# List of languages to synthesize
Languages = list(DEFAULT_TEXT.keys())

# Speaking speed
speed = 1.0

for language in Languages:
    print(f"Generating speech for [{language}]...")

    # Load model
    # if you want to load model from hugging face
    model = TTS(language=language, device="auto", use_hf=True)
    # or if you want to load from your own directory
    # model = TTS(language=language, device="auto", use_hf=False, local_repo_path_dict=LANG_TO_LOCAL_REPO_ID)

    # Get speaker information
    speaker_ids = model.hps.data.spk2id
    speaker = list(speaker_ids.keys())[0]
    speaker_id = speaker_ids[speaker]

    # Select text
    text = DEFAULT_TEXT[language]

    # Define output file path
    output_path = f"{language}.wav"

    # Run synthesis
    model.tts_to_file(
        text=text,
        speaker_id=speaker_id,
        output_path=output_path,
        speed=speed,
        quiet=True
    )

    print(f"Saved: {output_path}")

```

---

## ğŸ’¾ Clone & Local Installation
```bash
git clone https://github.com/kijoongkwon99/DMTTS.git
cd DMTTS
pip install -e .
python -m unidic download
```

---

---
## ğŸ’¾ Model & Config Installation


You can easily download pre-trained **DMTTS** models for each supported language from **Hugging Face**.

### ğŸ“ Download Path in Source Code
All model download and configuration logic is implemented in: `dmtts/src/utils/download_utils.py`

### ğŸŒ Supported Languages
```
# When downloading from Hugging Face Hub
LANG_TO_HF_REPO_ID = {
    'EN': 'kijoongkwon99/DMTTS-English',
    'JP': 'kijoongkwon99/DMTTS-Japanese',
    'ZH': 'kijoongkwon99/DMTTS-Chinese',
    'KR': 'kijoongkwon99/DMTTS-Korean',
    'TH': 'kijoongkwon99/DMTTS-Thai',
    'VI': 'kijoongkwon99/DMTTS-Vietnamese',
}

```
If you want to load models locally instead of from Hugging Face,<br>
make sure that BOTH of the following files exist inside each directory:<br>
  - checkpoint.pth  â†’ the model weights
  - config.json     â†’ the model configuration
<br>

Example:<br>
/to/your/local/path/<br>
&nbsp;&nbsp;&nbsp;&nbsp;â”œâ”€â”€ checkpoint.pth<br>
&nbsp;&nbsp;&nbsp;&nbsp;â””â”€â”€ config.json<br>
Otherwise, local loading will fail and you may need to re-download them.

---



---
## ğŸ“ Project Structure

```
DMTTS/
â”‚
â”œâ”€â”€ ckpts/                             # Model checkpoints
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ data/                              # Dataset folder
â”‚
â””â”€â”€ src/dmtts/
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ app/                           # API / Main entrypoints
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ api.py
    â”‚   â”œâ”€â”€ app.py
    â”‚   â”œâ”€â”€ main.py
    â”‚   â””â”€â”€ README.md
    â”‚
    â”œâ”€â”€ eval/                          # Evaluation scripts
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ ecapa_tdnn.py
    â”‚   â”œâ”€â”€ eval_infer_batch.py
    â”‚   â”œâ”€â”€ eval_metric_batch.py
    â”‚   â”œâ”€â”€ infer_metric_batch.sh
    â”‚   â”œâ”€â”€ result/
    â”‚   â””â”€â”€ README.md
    â”‚
    â”œâ”€â”€ infer/                         # Inference scripts
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ infer_cli.py
    â”‚   â”œâ”€â”€ outputs/
    â”‚   â””â”€â”€ README.md
    â”‚
    â”œâ”€â”€ model/                         # Model architecture
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ backbones/                 
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ discriminators.py
    â”‚   â”‚   â”œâ”€â”€ duration_predictors.py
    â”‚   â”‚   â”œâ”€â”€ encoders.py
    â”‚   â”‚   â”œâ”€â”€ flows.py
    â”‚   â”‚   â””â”€â”€ generators.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ monotonic_align/           # Alignment functions
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ core.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ text/                      # Text processing modules
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ chinese.py
    â”‚   â”‚   â”œâ”€â”€ cleaner.py
    â”‚   â”‚   â”œâ”€â”€ english.py
    â”‚   â”‚   â”œâ”€â”€ japanese.py
    â”‚   â”‚   â”œâ”€â”€ korean.py
    â”‚   â”‚   â”œâ”€â”€ kr_normalizer.py
    â”‚   â”‚   â”œâ”€â”€ symbols.py
    â”‚   â”‚   â”œâ”€â”€ thai.py
    â”‚   â”‚   â”œâ”€â”€ tone_sandhi.py
    â”‚   â”‚   â”œâ”€â”€ vietnamese.py
    â”‚   â”‚   â”œâ”€â”€ english_utils/         # English text normalization utils
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ abbreviations.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ number_norm.py
    â”‚   â”‚   â”‚   â””â”€â”€ time_norm.py
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â”‚
    â”‚   â”œâ”€â”€ attentions.py
    â”‚   â”œâ”€â”€ commons.py
    â”‚   â”œâ”€â”€ modules.py
    â”‚   â”œâ”€â”€ synthesizer.py
    â”‚   â””â”€â”€ transforms.py
    â”‚
    â”œâ”€â”€ train/                         # Training scripts & configs
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ train.py
    â”‚   â”œâ”€â”€ losses.py
    â”‚   â”œâ”€â”€ preprocess_text.py
    â”‚   â”œâ”€â”€ mel_processing.py
    â”‚   â”œâ”€â”€ train.sh
    â”‚   â””â”€â”€ README.md
    â”‚
    â””â”€â”€ utils/                         # Helper modules
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ data_utils.py
        â”œâ”€â”€ download_utils.py
        â”œâ”€â”€ hparam_utils.py
        â”œâ”€â”€ infer_utils.py
        â””â”€â”€ eval_utils.py

```

---
